{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":320111,"sourceType":"datasetVersion","datasetId":134715},{"sourceId":8873487,"sourceType":"datasetVersion","datasetId":5340943}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers[torch] accelerate -U\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-06T00:29:12.407703Z","iopub.execute_input":"2024-07-06T00:29:12.407984Z","iopub.status.idle":"2024-07-06T00:29:25.196485Z","shell.execute_reply.started":"2024-07-06T00:29:12.407959Z","shell.execute_reply":"2024-07-06T00:29:25.195262Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.32.1)\nRequirement already satisfied: transformers[torch] in /opt/conda/lib/python3.10/site-packages (4.42.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.23.2)\nRequirement already satisfied: numpy<2.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.4.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (4.66.4)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.1.2)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (2024.3.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers[torch]) (3.1.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->transformers[torch]) (2.1.3)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->transformers[torch]) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom transformers import BertTokenizer,AutoTokenizer\n\n# Load your data\ndf = pd.read_csv('/kaggle/input/hatedataset/hateDataset.csv')\ndf.reset_index(drop=True, inplace=True)\n# Encode the labels\nle = LabelEncoder()\ndf['label'] = le.fit_transform(df['label'])\n\n\n# Split the data and reset the indices\ntrain_texts, test_texts, train_labels, test_labels = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)\ntrain_texts.reset_index(drop=True, inplace=True)\ntest_texts.reset_index(drop=True, inplace=True)\ntrain_labels.reset_index(drop=True, inplace=True)\ntest_labels.reset_index(drop=True, inplace=True)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-06T12:34:26.651054Z","iopub.execute_input":"2024-07-06T12:34:26.651671Z","iopub.status.idle":"2024-07-06T12:34:33.744652Z","shell.execute_reply.started":"2024-07-06T12:34:26.651639Z","shell.execute_reply":"2024-07-06T12:34:33.743648Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df.","metadata":{"execution":{"iopub.status.busy":"2024-07-06T00:45:20.611131Z","iopub.execute_input":"2024-07-06T00:45:20.611484Z","iopub.status.idle":"2024-07-06T00:45:20.619802Z","shell.execute_reply.started":"2024-07-06T00:45:20.611459Z","shell.execute_reply":"2024-07-06T00:45:20.618608Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"534872"},"metadata":{}}]},{"cell_type":"code","source":"# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained('prajjwal1/bert-medium')\n\n# Tokenize the text\ntrain_encodings = tokenizer(train_texts.tolist(), truncation=True, padding=True, max_length=128)\ntest_encodings = tokenizer(test_texts.tolist(), truncation=True, padding=True, max_length=128)","metadata":{"execution":{"iopub.status.busy":"2024-07-06T00:45:27.472152Z","iopub.execute_input":"2024-07-06T00:45:27.473011Z","iopub.status.idle":"2024-07-06T00:45:31.800821Z","shell.execute_reply.started":"2024-07-06T00:45:27.472980Z","shell.execute_reply":"2024-07-06T00:45:31.799713Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\n\nclass HateSpeechDataset(Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\ntrain_dataset = HateSpeechDataset(train_encodings, train_labels)\ntest_dataset = HateSpeechDataset(test_encodings, test_labels)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-06T00:45:36.152255Z","iopub.execute_input":"2024-07-06T00:45:36.152598Z","iopub.status.idle":"2024-07-06T00:45:36.161919Z","shell.execute_reply.started":"2024-07-06T00:45:36.152572Z","shell.execute_reply":"2024-07-06T00:45:36.160756Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"from transformers import BertForSequenceClassification,AutoModelForSequenceClassification, Trainer, TrainingArguments\n\nmodel = AutoModelForSequenceClassification.from_pretrained('prajjwal1/bert-medium', num_labels=2)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-06T00:45:48.401089Z","iopub.execute_input":"2024-07-06T00:45:48.401984Z","iopub.status.idle":"2024-07-06T00:45:48.812085Z","shell.execute_reply.started":"2024-07-06T00:45:48.401949Z","shell.execute_reply":"2024-07-06T00:45:48.811085Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-medium and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir='./results',\n    num_train_epochs=2,\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    warmup_steps=500,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    logging_steps=200,\n    eval_strategy=\"steps\",\n    save_steps=200,\n    gradient_accumulation_steps=8,\n    fp16=True\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-06T00:46:05.251973Z","iopub.execute_input":"2024-07-06T00:46:05.252368Z","iopub.status.idle":"2024-07-06T00:46:05.285161Z","shell.execute_reply.started":"2024-07-06T00:46:05.252340Z","shell.execute_reply":"2024-07-06T00:46:05.284090Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset\n)\n\n# Train the model\ntrainer.train()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-06T00:46:17.479292Z","iopub.execute_input":"2024-07-06T00:46:17.480035Z","iopub.status.idle":"2024-07-06T00:58:06.739134Z","shell.execute_reply.started":"2024-07-06T00:46:17.479990Z","shell.execute_reply":"2024-07-06T00:58:06.737946Z"},"trusted":true},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2056' max='2056' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2056/2056 11:48, Epoch 1/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>200</td>\n      <td>0.672900</td>\n      <td>0.612100</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.579200</td>\n      <td>0.533996</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.548400</td>\n      <td>0.494191</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.500300</td>\n      <td>0.489087</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.490700</td>\n      <td>0.447344</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.402900</td>\n      <td>0.492378</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>0.403200</td>\n      <td>0.443560</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>0.399500</td>\n      <td>0.447581</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>0.388600</td>\n      <td>0.439837</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.382100</td>\n      <td>0.435257</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2056, training_loss=0.47407610592675115, metrics={'train_runtime': 708.5683, 'train_samples_per_second': 92.906, 'train_steps_per_second': 2.902, 'total_flos': 1287631287089664.0, 'train_loss': 0.47407610592675115, 'epoch': 1.9987847855146432})"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# Get predictions\npreds_output = trainer.predict(test_dataset)\npreds = torch.argmax(torch.tensor(preds_output.predictions), axis=1)\n\n# Generate classification report\nprint(classification_report(test_labels, preds, target_names=le.classes_))\n","metadata":{"execution":{"iopub.status.busy":"2024-07-06T00:58:33.147383Z","iopub.execute_input":"2024-07-06T00:58:33.148275Z","iopub.status.idle":"2024-07-06T00:58:54.504181Z","shell.execute_reply.started":"2024-07-06T00:58:33.148240Z","shell.execute_reply":"2024-07-06T00:58:54.503110Z"},"trusted":true},"execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n        hate       0.78      0.85      0.81      4376\n     nothate       0.81      0.72      0.76      3853\n\n    accuracy                           0.79      8229\n   macro avg       0.79      0.79      0.79      8229\nweighted avg       0.79      0.79      0.79      8229\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# Assuming you have already obtained predictions 'preds' and true labels 'test_labels'\n# preds = torch.argmax(torch.tensor(preds_output.predictions), axis=1)\n\n# Generate classification report\nreport = classification_report(test_labels, preds, target_names=le.classes_, output_dict=True)\n\n# Print the classification report\nprint(\"Classification Report:\")\nprint(classification_report(test_labels, preds, target_names=le.classes_))\n\n# Extract precision and F1-score for each class and overall\noverall_precision = report['accuracy']\noverall_f1_score = report['weighted avg']['f1-score']\n\n# Individual precision and F1-score for each class\nprecision_hate = report['hate']['precision']\nprecision_nothate = report['nothate']['precision']\n\nf1_score_hate = report['hate']['f1-score']\nf1_score_nothate = report['nothate']['f1-score']\n\n# Print overall metrics\nprint(f\"Overall Accuracy: {overall_precision:.2f}\")\nprint(f\"Overall F1-Score: {overall_f1_score:.2f}\")\n\n# Print individual metrics\nprint(f\"Precision for 'hate': {precision_hate:.2f}\")\nprint(f\"Precision for 'nothate': {precision_nothate:.2f}\")\n\nprint(f\"F1-Score for 'hate': {f1_score_hate:.2f}\")\nprint(f\"F1-Score for 'nothate': {f1_score_nothate:.2f}\")\nprint(\"bert-medium\")","metadata":{"execution":{"iopub.status.busy":"2024-07-06T00:59:00.590971Z","iopub.execute_input":"2024-07-06T00:59:00.591665Z","iopub.status.idle":"2024-07-06T00:59:00.629728Z","shell.execute_reply.started":"2024-07-06T00:59:00.591630Z","shell.execute_reply":"2024-07-06T00:59:00.628428Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Classification Report:\n              precision    recall  f1-score   support\n\n        hate       0.78      0.85      0.81      4376\n     nothate       0.81      0.72      0.76      3853\n\n    accuracy                           0.79      8229\n   macro avg       0.79      0.79      0.79      8229\nweighted avg       0.79      0.79      0.79      8229\n\nOverall Accuracy: 0.79\nOverall F1-Score: 0.79\nPrecision for 'hate': 0.78\nPrecision for 'nothate': 0.81\nF1-Score for 'hate': 0.81\nF1-Score for 'nothate': 0.76\nbert-medium\n","output_type":"stream"}]}]}